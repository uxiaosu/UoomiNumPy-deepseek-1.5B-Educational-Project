#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–æ•ˆæœæµ‹è¯•è„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºæµ‹è¯•ä¸åŒä¼˜åŒ–çº§åˆ«çš„æ•ˆæœï¼ŒåŒ…æ‹¬ï¼š
1. ç”Ÿæˆé€Ÿåº¦å¯¹æ¯”
2. Tokenç”¨é‡å¯¹æ¯”
3. å†…å­˜ä½¿ç”¨å¯¹æ¯”
4. è¾“å‡ºè´¨é‡å¯¹æ¯”
"""

import time
import sys
import os

# Add the parent directory to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.api import DeepSeekNumPy
from optimization_config import OptimizationConfig

def test_optimization_levels(model_dir: str):
    """æµ‹è¯•ä¸åŒä¼˜åŒ–çº§åˆ«çš„æ•ˆæœ
    
    Args:
        model_dir: æ¨¡å‹ç›®å½•è·¯å¾„
    """
    print("ğŸ§ª DeepSeekæ¨¡å‹ä¼˜åŒ–æ•ˆæœæµ‹è¯•")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¦ åŠ è½½æ¨¡å‹...")
    model = DeepSeekNumPy(model_dir)
    
    # æµ‹è¯•prompt
    test_prompt = "äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•è¶‹åŠ¿æ˜¯"
    
    # æµ‹è¯•ä¸åŒä¼˜åŒ–çº§åˆ«
    optimization_levels = [
        ('debug', OptimizationConfig.DEBUG_CONFIG),
        ('high_efficiency', OptimizationConfig.HIGH_EFFICIENCY),
        ('basic', OptimizationConfig.BASIC_OPTIMIZATION),
        ('quality', OptimizationConfig.QUALITY_OPTIMIZATION)
    ]
    
    results = []
    
    for level_name, config in optimization_levels:
        print(f"\nğŸ”§ æµ‹è¯• {level_name} ä¼˜åŒ–çº§åˆ«")
        print("-" * 40)
        print(f"å‚æ•°: max_tokens={config['max_new_tokens']}, temp={config['temperature']}, top_p={config['top_p']}")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        try:
            # ç”Ÿæˆæ–‡æœ¬
            response = model.generate(
                prompt=test_prompt,
                max_new_tokens=config['max_new_tokens'],
                temperature=config['temperature'],
                top_p=config['top_p'],
                top_k=config['top_k'],
                verbose=False  # å…³é—­è¯¦ç»†è¾“å‡ºä»¥å‡†ç¡®æµ‹é‡æ—¶é—´
            )
            
            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            generation_time = end_time - start_time
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            response_length = len(response)
            tokens_per_second = config['max_new_tokens'] / generation_time if generation_time > 0 else 0
            
            # ä¿å­˜ç»“æœ
            result = {
                'level': level_name,
                'config': config,
                'response': response,
                'generation_time': generation_time,
                'response_length': response_length,
                'tokens_per_second': tokens_per_second
            }
            results.append(result)
            
            # æ˜¾ç¤ºç»“æœ
            print(f"â±ï¸  ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
            print(f"ğŸ“ å“åº”é•¿åº¦: {response_length}å­—ç¬¦")
            print(f"âš¡ ç”Ÿæˆé€Ÿåº¦: {tokens_per_second:.1f} tokens/ç§’")
            print(f"ğŸ“ ç”Ÿæˆå†…å®¹: {response[:100]}{'...' if len(response) > 100 else ''}")
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            continue
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print("\nğŸ“Š ä¼˜åŒ–æ•ˆæœå¯¹æ¯”")
    print("=" * 60)
    print(f"{'çº§åˆ«':<15} {'æ—¶é—´(ç§’)':<10} {'é€Ÿåº¦(t/s)':<12} {'é•¿åº¦':<8} {'æ•ˆç‡è¯„åˆ†':<10}")
    print("-" * 60)
    
    # è®¡ç®—æ•ˆç‡è¯„åˆ† (é€Ÿåº¦ / æ—¶é—´)
    for result in results:
        efficiency_score = result['tokens_per_second'] / result['generation_time'] if result['generation_time'] > 0 else 0
        print(f"{result['level']:<15} {result['generation_time']:<10.2f} {result['tokens_per_second']:<12.1f} {result['response_length']:<8} {efficiency_score:<10.2f}")
    
    # æ¨èæœ€ä½³é…ç½®
    if results:
        fastest = max(results, key=lambda x: x['tokens_per_second'])
        most_efficient = max(results, key=lambda x: x['tokens_per_second'] / x['generation_time'] if x['generation_time'] > 0 else 0)
        
        print("\nğŸ† æ¨èé…ç½®")
        print("-" * 30)
        print(f"âš¡ æœ€å¿«é€Ÿåº¦: {fastest['level']} ({fastest['tokens_per_second']:.1f} tokens/ç§’)")
        print(f"ğŸ¯ æœ€é«˜æ•ˆç‡: {most_efficient['level']} (æ•ˆç‡è¯„åˆ†: {most_efficient['tokens_per_second'] / most_efficient['generation_time']:.2f})")
    
    return results

def show_optimization_recommendations():
    """æ˜¾ç¤ºä¼˜åŒ–å»ºè®®"""
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®")
    print("=" * 40)
    
    recommendations = [
        "1. ğŸš€ æ—¥å¸¸ä½¿ç”¨æ¨è 'basic' é…ç½® - å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡",
        "2. âš¡ è¿½æ±‚é€Ÿåº¦ä½¿ç”¨ 'high_efficiency' é…ç½® - æœ€å¿«å“åº”",
        "3. ğŸ¨ é‡è§†è´¨é‡ä½¿ç”¨ 'quality' é…ç½® - æ›´å¥½çš„è¾“å‡º",
        "4. ğŸ”§ è°ƒè¯•é—®é¢˜ä½¿ç”¨ 'debug' é…ç½® - è¯¦ç»†ä¿¡æ¯",
        "5. ğŸ“± ç§»åŠ¨è®¾å¤‡æˆ–ä½é…ç½®æœºå™¨å»ºè®®ä½¿ç”¨ 'high_efficiency'",
        "6. ğŸ–¥ï¸  é«˜æ€§èƒ½æœºå™¨å¯ä»¥ä½¿ç”¨ 'quality' è·å¾—æ›´å¥½ä½“éªŒ",
        "7. ğŸ’¾ å†…å­˜ä¸è¶³æ—¶å‡å°‘ max_new_tokens å‚æ•°",
        "8. ğŸ”„ é•¿å¯¹è¯æ—¶å®šæœŸæ¸…ç†å†å²è®°å½•"
    ]
    
    for rec in recommendations:
        print(rec)

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python test_optimization.py <æ¨¡å‹ç›®å½•>")
        print("ç¤ºä¾‹: python test_optimization.py ./examples/weights/deepseek_numpy_weights")
        sys.exit(1)
    
    model_dir = sys.argv[1]
    
    try:
        # æµ‹è¯•ä¼˜åŒ–æ•ˆæœ
        results = test_optimization_levels(model_dir)
        
        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
        show_optimization_recommendations()
        
        print("\nâœ… ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()