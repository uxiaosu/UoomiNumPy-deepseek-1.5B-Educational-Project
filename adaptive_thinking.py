#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªé€‚åº”æ€è€ƒç”Ÿæˆå™¨ - AIè‡ªä¸»ç”Ÿæˆæ€è€ƒæ¨¡æ¿
è®©AIæ ¹æ®é—®é¢˜è‡ªç„¶åœ°ç”Ÿæˆæ€è€ƒè¿‡ç¨‹ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å›ºå®šæ¨¡æ¿
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from api import DeepSeekNumPy
import re

class AdaptiveThinkingGenerator:
    """è‡ªé€‚åº”æ€è€ƒç”Ÿæˆå™¨ï¼Œè®©AIè‡ªä¸»ç”Ÿæˆæ€è€ƒè¿‡ç¨‹ã€‚"""
    
    def __init__(self, model_dir: str):
        """åˆå§‹åŒ–è‡ªé€‚åº”æ€è€ƒç”Ÿæˆå™¨ã€‚"""
        print("ğŸš€ åˆå§‹åŒ–è‡ªé€‚åº”æ€è€ƒç”Ÿæˆå™¨...")
        self.model = DeepSeekNumPy(model_dir)
        print("âœ… åˆå§‹åŒ–å®Œæˆï¼")
    
    def generate_thinking_prompt(self, user_question: str, max_tokens: int = 30):
        """è®©AIè‡ªå·±ç”Ÿæˆæ€è€ƒæç¤ºè¯ã€‚"""
        
        # è®©AIç”Ÿæˆæ€è€ƒæ¡†æ¶çš„æç¤º
        meta_prompt = f"""<ï½œUserï½œ>ç”¨æˆ·é—®äº†è¿™ä¸ªé—®é¢˜ï¼š"{user_question}"

è¯·ä¸ºè¿™ä¸ªé—®é¢˜è®¾è®¡ä¸€ä¸ªæ€è€ƒæ¡†æ¶ã€‚ä½ éœ€è¦ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æ€è€ƒæç¤ºï¼Œå‘Šè¯‰AIåº”è¯¥å¦‚ä½•æ€è€ƒè¿™ä¸ªé—®é¢˜ã€‚

è¦æ±‚ï¼š
1. ä¸è¦ç›´æ¥å›ç­”é—®é¢˜
2. åªç”Ÿæˆæ€è€ƒçš„æ–¹å‘å’Œæ­¥éª¤
3. ä¿æŒç®€æ´ï¼Œä¸è¶…è¿‡3-4ä¸ªè¦ç‚¹
4. é€‚åˆè¿™ä¸ªå…·ä½“é—®é¢˜çš„ç‰¹ç‚¹

æ€è€ƒæ¡†æ¶ï¼š<ï½œAssistantï½œ>é’ˆå¯¹é—®é¢˜"{user_question}"ï¼Œæˆ‘å»ºè®®æŒ‰ä»¥ä¸‹æ–¹å¼æ€è€ƒï¼š

"""
        
        print("ğŸ§  AIæ­£åœ¨ç”Ÿæˆæ€è€ƒæ¡†æ¶...")
        thinking_framework = self.model.generate(
            meta_prompt,
            max_new_tokens=max_tokens,
            temperature=0.8,
            top_p=0.9,
            repetition_penalty=1.1,
            verbose=False
        )
        
        return thinking_framework.strip()
    
    def generate_with_adaptive_thinking(self, user_question: str, max_tokens: int = 50):
        """ä½¿ç”¨è‡ªé€‚åº”æ€è€ƒæ¨¡å¼ç”Ÿæˆå›ç­”ã€‚"""
        
        print(f"\nğŸ“ ç”¨æˆ·é—®é¢˜: {user_question}")
        print("=" * 60)
        
        # ç¬¬ä¸€æ­¥ï¼šè®©AIç”Ÿæˆæ€è€ƒæ¡†æ¶
        thinking_framework = self.generate_thinking_prompt(user_question, max_tokens=25)
        print(f"\nğŸ¯ AIç”Ÿæˆçš„æ€è€ƒæ¡†æ¶:\n{thinking_framework}")
        print("-" * 40)
        
        # ç¬¬äºŒæ­¥ï¼šåŸºäºç”Ÿæˆçš„æ¡†æ¶è¿›è¡Œæ€è€ƒå’Œå›ç­”
        adaptive_prompt = f"""<ï½œUserï½œ>{user_question}<ï½œAssistantï½œ><think>
{thinking_framework}

ç°åœ¨è®©æˆ‘æŒ‰ç…§è¿™ä¸ªæ¡†æ¶æ¥æ€è€ƒï¼š

</think>

åŸºäºæˆ‘çš„æ€è€ƒï¼Œæˆ‘çš„å›ç­”æ˜¯ï¼š"""
        
        print("ğŸ¤” AIæ­£åœ¨æŒ‰ç…§è‡ªå·±çš„æ¡†æ¶æ€è€ƒ...")
        response = self.model.generate(
            adaptive_prompt,
            max_new_tokens=max_tokens,
            temperature=0.7,
            top_p=0.9,
            repetition_penalty=1.1,
            verbose=True
        )
        
        return response
    
    def extract_thinking_and_response(self, full_response: str):
        """ä»å®Œæ•´å›ç­”ä¸­æå–æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆå›ç­”ã€‚"""
        
        # æŸ¥æ‰¾ <think> æ ‡ç­¾
        think_pattern = r'<think>(.*?)</think>'
        think_match = re.search(think_pattern, full_response, re.DOTALL)
        
        if think_match:
            thinking_process = think_match.group(1).strip()
            # ç§»é™¤æ€è€ƒéƒ¨åˆ†ï¼Œè·å–æœ€ç»ˆå›ç­”
            final_response = re.sub(think_pattern, '', full_response, flags=re.DOTALL).strip()
        else:
            thinking_process = "æœªæ£€æµ‹åˆ°æ€è€ƒè¿‡ç¨‹"
            final_response = full_response
        
        return thinking_process, final_response
    
    def pure_adaptive_thinking(self, user_question: str, max_tokens: int = 60):
        """çº¯è‡ªé€‚åº”æ€è€ƒæ¨¡å¼ - å®Œå…¨è®©AIè‡ªä¸»å†³å®šå¦‚ä½•æ€è€ƒã€‚"""
        
        print(f"\nğŸ“ ç”¨æˆ·é—®é¢˜: {user_question}")
        print("=" * 60)
        print("ğŸ§  å¯ç”¨çº¯è‡ªé€‚åº”æ€è€ƒæ¨¡å¼...")
        
        # å®Œå…¨å¼€æ”¾çš„æç¤ºï¼Œè®©AIè‡ªä¸»å†³å®šæ€è€ƒæ–¹å¼
        open_prompt = f"""<ï½œUserï½œ>{user_question}<ï½œAssistantï½œ><think>
è®©æˆ‘ä»”ç»†æ€è€ƒè¿™ä¸ªé—®é¢˜...

</think>

"""
        
        response = self.model.generate(
            open_prompt,
            max_new_tokens=max_tokens,
            temperature=0.8,
            top_p=0.9,
            repetition_penalty=1.1,
            verbose=True
        )
        
        return response

def main():
    """ä¸»å‡½æ•° - è‡ªé€‚åº”æ€è€ƒç”Ÿæˆå™¨ã€‚"""
    print("ğŸ¯ DeepSeek è‡ªé€‚åº”æ€è€ƒç”Ÿæˆå™¨")
    print("=" * 60)
    print("ğŸ’¡ AIå°†è‡ªä¸»ç”Ÿæˆæ€è€ƒæ¨¡æ¿å’Œè¿‡ç¨‹")
    print("ğŸ§  æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š")
    print("   1. æ¡†æ¶ç”Ÿæˆæ¨¡å¼ï¼šAIå…ˆç”Ÿæˆæ€è€ƒæ¡†æ¶ï¼Œå†æŒ‰æ¡†æ¶æ€è€ƒ")
    print("   2. çº¯è‡ªé€‚åº”æ¨¡å¼ï¼šAIå®Œå…¨è‡ªä¸»å†³å®šæ€è€ƒæ–¹å¼")
    print("âš¡ å·²ä¼˜åŒ–ç”Ÿæˆé€Ÿåº¦")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    model_dir = "../DeepSeek-R1-Distill-Qwen-1.5B"
    generator = AdaptiveThinkingGenerator(model_dir)
    
    print("\nğŸ® å¼€å§‹äº¤äº’æ¨¡å¼ï¼")
    print("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºï¼‰ï¼š")
    print("ğŸ”§ è¾“å…¥ 'mode' åˆ‡æ¢æ€è€ƒæ¨¡å¼")
    print("-" * 60)
    
    current_mode = "adaptive"  # adaptive æˆ– pure
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input(f"\nâ“ æ‚¨çš„é—®é¢˜ [{current_mode}æ¨¡å¼]: ").strip()
            
            # æ£€æŸ¥é€€å‡ºæ¡ä»¶
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼å†è§ï¼")
                break
            
            # åˆ‡æ¢æ¨¡å¼
            if user_input.lower() == 'mode':
                current_mode = "pure" if current_mode == "adaptive" else "adaptive"
                mode_name = "çº¯è‡ªé€‚åº”æ¨¡å¼" if current_mode == "pure" else "æ¡†æ¶ç”Ÿæˆæ¨¡å¼"
                print(f"\nğŸ”„ å·²åˆ‡æ¢åˆ°ï¼š{mode_name}")
                continue
            
            if not user_input:
                print("âš ï¸  è¯·è¾“å…¥ä¸€ä¸ªé—®é¢˜")
                continue
            
            # æ ¹æ®æ¨¡å¼ç”Ÿæˆå›ç­”
            print("\nğŸ”„ æ­£åœ¨ç”Ÿæˆå›ç­”...")
            
            if current_mode == "adaptive":
                response = generator.generate_with_adaptive_thinking(user_input, max_tokens=40)
            else:
                response = generator.pure_adaptive_thinking(user_input, max_tokens=50)
            
            # æå–æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆå›ç­”
            thinking, final_answer = generator.extract_thinking_and_response(response)
            
            print("\n" + "=" * 60)
            print("ğŸ§  AIçš„æ€è€ƒè¿‡ç¨‹:")
            print("-" * 30)
            print(thinking)
            
            print("\nğŸ’¡ æœ€ç»ˆå›ç­”:")
            print("-" * 30)
            print(final_answer)
            print("=" * 60)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
            print("è¯·é‡è¯•æˆ–è¾“å…¥æ–°é—®é¢˜")

if __name__ == "__main__":
    main()